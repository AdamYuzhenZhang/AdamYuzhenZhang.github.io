<!DOCTYPE HTML>
<!--
	Phantom by HTML5 UP
	html5up.net | @ajlkn
	Free for personal and commercial use under the CCA 3.0 license (html5up.net/license)
-->
<html>

<head>
    <title>Interactive Device Design</title>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no" />
    <link rel="stylesheet" href="assets/css/main.css" />
    <noscript>
        <link rel="stylesheet" href="assets/css/noscript.css" />
    </noscript>
</head>

<body class="is-preload">
<!-- Wrapper -->
<div id="wrapper">

    <!-- Header -->
    <header id="header">
        <div class="inner">
            <!-- Logo -->
            <a href="index.html" class="logo">
                <span class="symbol"><img src="images/Logo.png" alt="" /></span><span class="title">Yuzhen</span>
            </a>
            <!-- Nav -->
            <nav>
                <ul>
                    <li><a href="index.html">Home</a></li>
                    <li><a href="projects.html">Portfolio</a></li>
                    <li><a href="contact.html">About</a></li>
                </ul>
            </nav>

        </div>
    </header>

    <!-- Main -->
    <div id="main">
        <div class="inner">
            <h1>Interactive Device Design</h1>
            <h3>Rapid Prototyping with Raspberry Pi</h3>
            <p>This series of two-week projects explores the potential of Raspberry Pi, digital fabrication,
                and computer vision in prototyping interactive devices and experiences.
            </p>

            <h2>Interactive Van Gogh</h2>
            <p><i>Collaborator</i>: Angela Chen, Kaiyuan Deng, Esther Fang, Ken He
                <br/><i>Contribution</i>: Design, fabrication, program architecture
                <br/>This exhibition consists of two interactive artworks:
                <br/>1. A portrait of Van Gogh whose eyelids, eyeballs, and eyebrows can move to form facial expressions
                in response to visitors’ body movements. The virtual Van Gogh could also “talk” to the visitors when
                he recognizes their hand gestures through computer vision.
                <br/>2. A canvas that constantly transforms its pixel colors between dark and light to reflect visitors’
                silhouettes. Three Raspberry Pis collaborate through the MQTT broker.
            </p>
            <div class="iframe-container">
                <iframe width="560" height="315" src="https://www.youtube.com/embed/EN9Ri0R0MEw" title="YouTube video player" 
                        frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" 
                        allowfullscreen></iframe>
            </div>
            <p> </p>
            <span class="image main"><img src="images/IDD/IDD.png" alt="" /></span>

            <h2>Squid Game - Red Light Green Light</h2>
            <p><i>Collaborator</i>: Esther Fang, Ken He
                <br/><i>Contribution</i>: Design, fabrication, implementation
                <br/>This project integrates a variety of sensors, and laser cut cardboard structure into the <i>Red Light,
                Green Light</i> game in the TV series, <i>the Squid Game</i>. The player’s goal is to reach the capacitive sensor
                by the doll but has to freeze when the doll turns. A controller sits behind the doll and manipulates
                the doll’s movement.
            </p>
            <div class="iframe-container">
                <iframe width="560" height="315" src="https://www.youtube.com/embed/W5WS1Kb7hN4" title="YouTube video player" frameborder="0" 
                        allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" 
                        allowfullscreen></iframe>
            </div>
            <p> </p>
            <span class="image main"><img src="images/IDD/IDD2.png" alt="" /></span>

            <h2>Smart Closet</h2>
            <p><i>Collaborator</i>: Esther Fang, Ken He
                <br/><i>Contribution</i>: Design, fabrication, implementation
                <br/>This smart closet obtains real-time weather data and detects the clothing the user is wearing with
                computer vision, based on which it gives the user recommendations about their outfit. Then a physical
                mechanism in the closet automatically brings the suggestion to the user. A to-scale proof-of-concept
                prototype was built with 3D printed components and cardboard.
            </p>
            <div class="iframe-container">
                <iframe width="560" height="315" src="https://www.youtube.com/embed/-F12KcUUEZ4" title="YouTube video player" frameborder="0" 
                        allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" 
                        allowfullscreen></iframe>
            </div>
            <p> </p>
            <span class="image main"><img src="images/IDD/IDD3.png" alt="" /></span>

            <h2>Whac-A-Mole</h2>
            <p><i>Collaborator</i>: Esther Fang, Ken He
                <br/><i>Contribution</i>: Design, fabrication, implementation
            </p>
            <div class="iframe-container">
                <iframe width="560" height="315" src="https://www.youtube.com/embed/cXkujgNt9Ig" title="YouTube video player"
                        frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"
                        allowfullscreen></iframe>
            </div>
            <p> </p>
            <a href="https://github.com/AdamYuzhenZhang/Interactive-Lab-Hub" target="_blank" class="button fit">GitHub Repository - Interactive-Lab-Hub</a>
            
        </div>
    </div>


</div>

<!-- Scripts -->
<script src="assets/js/jquery.min.js"></script>
<script src="assets/js/browser.min.js"></script>
<script src="assets/js/breakpoints.min.js"></script>
<script src="assets/js/util.js"></script>
<script src="assets/js/main.js"></script>

</body>

</html>